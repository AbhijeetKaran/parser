{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class tabFileReader:\n",
    "    def __init__(self,filename,bioFileType,metainfo_sep,val_sep):\n",
    "        self.filename = filename\n",
    "        self.fileType = bioFileType\n",
    "        self.fileobj = open(filename,'r')\n",
    "        self.colSep = metainfo_sep\n",
    "        self.valSep = val_sep\n",
    "\n",
    "        # set header for data based on file type\n",
    "        self.fileHeader()\n",
    "                \n",
    "        # parse data from tab seperated file\n",
    "        self.data = None \n",
    "        self.dataParser()\n",
    "\n",
    "\n",
    "#@ based on biological file type provides header file\n",
    "    def fileHeader(self):\n",
    "        if self.fileType == \"gtf\" or self.fileType == \"gff\":\n",
    "            self.column_names = [\"Seqname\",\"Source\",\"feature\",\"Start\",\"End\",\"score\",\"strand\",\"frame\",\"attribute\"]\n",
    "        elif self.fileType == \"bed\":\n",
    "            self.column_names = []\n",
    "        else:\n",
    "            self.column_names = []\n",
    "\n",
    "#@ retrive index of Documneted/commented lines\n",
    "    def retriveCommentIndex(self):\n",
    "        indx = []\n",
    "        self.fileobj.seek(0)\n",
    "        for ix,l in enumerate(self.fileobj):\n",
    "            if l[0] == '#':\n",
    "                indx.append(ix)\n",
    "        self.fileobj.seek(0)\n",
    "        return indx\n",
    "\n",
    "#@ get MetaData from the file \n",
    "    def getMetaData(self):\n",
    "        skip_index = self.retriveCommentIndex()\n",
    "        filetxt = self.fileobj.readlines()\n",
    "        for lineidx in skip_index:\n",
    "            print(filetxt[lineidx],end=\"\")\n",
    "        self.fileobj.seek(0)\n",
    "\n",
    "#@ Transforming attribute data into columns\n",
    "    def attributeDataTransform(self,stng,v):\n",
    "        temp_dict = {}\n",
    "        for i in stng:\n",
    "            i = i.strip().split(v)\n",
    "            if len(i) == 1:\n",
    "                if i[0] != \" \":\n",
    "                    temp_dict[\"extra\"] = i[0].strip()\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                temp_dict[i[0].strip()] = i[1].strip()\n",
    "        return temp_dict\n",
    "\n",
    "#@ new Reads the content of GTF/GFF file into a pandas dataframe\n",
    "    def dataParser(self):\n",
    "        self.data = pd.read_csv(self.fileobj,sep='\\t',header=None,names=self.column_names,comment='#')\n",
    "        # Transforming attribute column values to columns takes time \n",
    "        newinfo = pd.DataFrame.from_dict(dict(self.data[\"attribute\"].str.split(self.colSep).apply(self.attributeDataTransform,v=self.valSep))).T\n",
    "        self.data = self.data.join(newinfo,how=\"left\")\n",
    "        self.data.drop(\"attribute\",axis=1,inplace=True)\n",
    "    \n",
    "    #Show tags in info column given single feature as string or multiple feature as list of string\n",
    "    def showgffFeatures(self,feature):\n",
    "        typ = type(feature) \n",
    "        if typ == str:\n",
    "            print(\"Common tags in feature :\")\n",
    "            print(\"  \",feature,\" : \",self.feature_objects[feature])\n",
    "        elif typ == list:\n",
    "            print(\"Common tags per feature :\")\n",
    "            for x in feature:\n",
    "                print(f\"\\t{x} : {self.feature_objects[x]}\")\n",
    "\n",
    "    #Get Common tags per features in gff file\n",
    "    def getFeatureTags(self):\n",
    "        feature_common_tags = {}\n",
    "        for features in self.feature_tags:\n",
    "            feature_data = self.data[self.data[\"feature\"] == features]\n",
    "            totalFeatureRows = len(feature_data)\n",
    "            info_tag_dict = {}\n",
    "            for idx,fd in feature_data[8].items():\n",
    "                info_col = fd.split(';')\n",
    "                for info_i in info_col:\n",
    "                    i_c = info_i.split('=')\n",
    "                    if i_c[0] not in info_tag_dict.keys():\n",
    "                        info_tag_dict[i_c[0]] = 1\n",
    "                    else:\n",
    "                        info_tag_dict[i_c[0]] = info_tag_dict[i_c[0]]+1\n",
    "            common_tags = []\n",
    "            for tag_counts in info_tag_dict.keys():\n",
    "                if info_tag_dict[tag_counts] == totalFeatureRows:\n",
    "                    common_tags.append(tag_counts)\n",
    "            feature_common_tags[features] = set(common_tags)\n",
    "        return feature_common_tags\n",
    "\n",
    "    #Feature tags intersection \n",
    "    def getCommonTagsAmongFeatures(self,features):\n",
    "        try:\n",
    "            if type(features) == list:\n",
    "                print()\n",
    "        except:\n",
    "            print()\n",
    "\n",
    "    #Extract data with a feature\n",
    "    def getDataWithSingleFeature(self,feature):\n",
    "        try:\n",
    "            if type(feature) != str:\n",
    "                print(f\"{error_color} ERROR : getDataWithFeature() gets data for single feature. Use getDataWithMultipleFeatures() for multiple feature.{color_end}\")\n",
    "                return\n",
    "            else:\n",
    "                header = self.commonHeader+list(self.feature_objects[feature])\n",
    "                feature_tags = list(self.feature_objects[feature])\n",
    "                feature_data = self.data[self.data[2] == feature]\n",
    "                feature_info = []\n",
    "                for i in range(0,len(feature_tags)):\n",
    "                    x = []\n",
    "                    feature_info.append(x)\n",
    "                for idx,fd in feature_data[8].items():\n",
    "                    info_col = fd.split(';')\n",
    "                    for info_i in info_col:\n",
    "                        i_c = info_i.split('=')\n",
    "                        for i_f in range(0,len(feature_tags)):\n",
    "                            if i_c[0] == feature_tags[i_f]:\n",
    "                                feature_info[i_f].append(i_c[1])\n",
    "                temp_data = feature_data.loc[:,[0,1,2,3,4,5,6,7]]\n",
    "                temp_data.columns = self.commonHeader\n",
    "                for tag_i in range(0,len(feature_tags)):\n",
    "                    temp_data[feature_tags[tag_i]] = feature_info[tag_i]\n",
    "                return temp_data\n",
    "        except:\n",
    "            if type(feature) == str:\n",
    "                print(f\"{error_color}ERROR : Feature \\\"{feature}\\\" do not exist in the file {self.filename} {color_end}\")\n",
    "\n",
    "    #Extract data with a set of features\n",
    "    def getDataWithMultipleFeatures(self,features):\n",
    "        try:\n",
    "            if type(features) != list:\n",
    "                print(f\"{error_color}ERROR : getDataWithMultipleFeatures() gets data for multiple feature, use getDataWithFeature() to get data for single feature..{color_end}\")\n",
    "            else:\n",
    "                common_subtags = {}\n",
    "                for t in range(0,len(features)):\n",
    "                    if t == 0:\n",
    "                        common_subtags = self.feature_objects[features[t]].intersection(self.feature_objects[features[t]])\n",
    "                    else:\n",
    "                        common_subtags = common_subtags.intersection(self.feature_objects[features[t]])\n",
    "                common_subtags = list(common_subtags)\n",
    "                header = self.commonHeader+common_subtags\n",
    "                mainTable = pd.DataFrame()\n",
    "                for feature in features:\n",
    "                    feature_data = self.data[self.data[2] == feature]\n",
    "                    feature_info = []\n",
    "                    for i in range(0,len(common_subtags)):\n",
    "                        x = []\n",
    "                        feature_info.append(x)\n",
    "                    for idx,fd in feature_data[8].items():\n",
    "                        info_col = fd.split(';')\n",
    "                        for info_i in info_col:\n",
    "                            i_c = info_i.split('=')\n",
    "                            for i_f in range(0,len(common_subtags)):\n",
    "                                if i_c[0] == common_subtags[i_f]:\n",
    "                                    feature_info[i_f].append(i_c[1])\n",
    "                    temp_data = feature_data.loc[:,[0,1,2,3,4,5,6,7]]\n",
    "                    temp_data.columns = self.commonHeader\n",
    "                    for tag_i in range(0,len(common_subtags)):\n",
    "                        temp_data[common_subtags[tag_i]] = feature_info[tag_i]\n",
    "                    mainTable = mainTable.append(temp_data)\n",
    "                return mainTable\n",
    "        except:\n",
    "            print(\"some random error in getdatawithmultiple feature\")\n",
    "\n",
    "    #Write data to file\n",
    "    def dataToFile(self,data,filename):\n",
    "        try:\n",
    "            data.to_csv(filename,sep=\"\\t\",index=False)\n",
    "            print(f\"{output_color}Data written to file: {filename}{color_end}\")\n",
    "        except:\n",
    "            print(f\"{error_color}ERROR : no file name provided\")\n",
    "\n",
    "    #Remove columns from data\n",
    "    def removeColumn(self,data,columnName):\n",
    "        try:\n",
    "            if type(columnName) == list:\n",
    "                for c_n in columnName:\n",
    "                    if c_n not in data.columns:\n",
    "                        print(f\"{error_color}Error: Column name {c_n} do not exist in the selected data{color_end}\")\n",
    "                    else:\n",
    "                        data.drop(columns=c_n)\n",
    "                        print(f\"{c_n} removed: done\")\n",
    "                return data\n",
    "            elif type(columnName) == str:\n",
    "                if columnName not in data.columns:\n",
    "                    print(f\"{error_color}Error: Column name {columnName} do not exist in the selected data{color_end}\")\n",
    "                else:\n",
    "                    data.drop(columns=columnName)\n",
    "                    print(f\"{columnName} removed: done\")\n",
    "                return data\n",
    "        except:\n",
    "            print(\"exception\")\n",
    "\n",
    "#@ Gives general information on GTF/GFF file   \n",
    "    def generalInfo(self):\n",
    "        seqPerCount = pd.DataFrame(self.data['Seqname'].value_counts())\n",
    "        print(f\"GTF/GFF source: {self.data['Source'].unique}\")\n",
    "        print(f\"No. of sequence set: {len(seqPerCount.index)}\")\n",
    "        print(f\"Sequence Set: {list(seqPerCount.index)}\")\n",
    "        print(seqPerCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading file and filetype\n",
    "filename = \"sample.gtf\"\n",
    "\n",
    "# read gtf file \n",
    "column_names = [\"Seqname\",\"Source\",\"feature\",\"Start\",\"End\",\"score\",\"strand\",\"frame\",\"attribute\"]\n",
    "data = pd.read_csv(filename,sep='\\t',header=None,names=column_names,comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seqname</th>\n",
       "      <th>Source</th>\n",
       "      <th>feature</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>frame</th>\n",
       "      <th>attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>transcript</td>\n",
       "      <td>11136</td>\n",
       "      <td>12457</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000001\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>exon</td>\n",
       "      <td>11136</td>\n",
       "      <td>11635</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000001\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>exon</td>\n",
       "      <td>11639</td>\n",
       "      <td>12457</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000001\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>transcript</td>\n",
       "      <td>11630</td>\n",
       "      <td>13433</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000002\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>exon</td>\n",
       "      <td>11630</td>\n",
       "      <td>11831</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000002\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>transcript</td>\n",
       "      <td>205297</td>\n",
       "      <td>238968</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>exon</td>\n",
       "      <td>205297</td>\n",
       "      <td>205629</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>exon</td>\n",
       "      <td>232825</td>\n",
       "      <td>233128</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>exon</td>\n",
       "      <td>236123</td>\n",
       "      <td>236229</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>chr1</td>\n",
       "      <td>Liftoff</td>\n",
       "      <td>exon</td>\n",
       "      <td>238528</td>\n",
       "      <td>238968</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seqname   Source     feature   Start     End score strand frame  \\\n",
       "0     chr1  Liftoff  transcript   11136   12457     .      -     .   \n",
       "1     chr1  Liftoff        exon   11136   11635     .      -     .   \n",
       "2     chr1  Liftoff        exon   11639   12457     .      -     .   \n",
       "3     chr1  Liftoff  transcript   11630   13433     .      +     .   \n",
       "4     chr1  Liftoff        exon   11630   11831     .      +     .   \n",
       "..     ...      ...         ...     ...     ...   ...    ...   ...   \n",
       "95    chr1  Liftoff  transcript  205297  238968     .      +     .   \n",
       "96    chr1  Liftoff        exon  205297  205629     .      +     .   \n",
       "97    chr1  Liftoff        exon  232825  233128     .      +     .   \n",
       "98    chr1  Liftoff        exon  236123  236229     .      +     .   \n",
       "99    chr1  Liftoff        exon  238528  238968     .      +     .   \n",
       "\n",
       "                                            attribute  \n",
       "0   transcript_id \"LOFF_T0000001\"; gene_id \"LOFF_G...  \n",
       "1   transcript_id \"LOFF_T0000001\"; gene_id \"LOFF_G...  \n",
       "2   transcript_id \"LOFF_T0000001\"; gene_id \"LOFF_G...  \n",
       "3   transcript_id \"LOFF_T0000002\"; gene_id \"LOFF_G...  \n",
       "4   transcript_id \"LOFF_T0000002\"; gene_id \"LOFF_G...  \n",
       "..                                                ...  \n",
       "95  transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...  \n",
       "96  transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...  \n",
       "97  transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...  \n",
       "98  transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...  \n",
       "99  transcript_id \"LOFF_T0000015\"; gene_id \"LOFF_G...  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Seqname        100 non-null    object\n",
      " 1   Source         100 non-null    object\n",
      " 2   feature        100 non-null    object\n",
      " 3   Start          100 non-null    int64 \n",
      " 4   End            100 non-null    int64 \n",
      " 5   score          100 non-null    object\n",
      " 6   strand         100 non-null    object\n",
      " 7   frame          100 non-null    object\n",
      " 8   transcript_id  100 non-null    object\n",
      " 9   gene_id        100 non-null    object\n",
      " 10  gene_name      100 non-null    object\n",
      " 11  extra          74 non-null     object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Transforming attribute column to multiple features \n",
    "def attributeDataTransform(stng,v):\n",
    "    temp_dict = {}\n",
    "    for i in stng:\n",
    "        i = i.strip().split(v)\n",
    "        if len(i) == 1:\n",
    "            if i[0] != \" \":\n",
    "                temp_dict[\"extra\"] = i[0].strip()\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            temp_dict[i[0].strip()] = i[1].strip()\n",
    "    return temp_dict\n",
    "\n",
    "\n",
    "newinfo = pd.DataFrame.from_dict(dict(data[\"attribute\"].str.split(\";\").apply(attributeDataTransform,v=\" \"))).T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(newinfo,how=\"left\")\n",
    "data.drop(\"attribute\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seqname          False\n",
       "Source           False\n",
       "feature          False\n",
       "Start            False\n",
       "End              False\n",
       "score            False\n",
       "strand           False\n",
       "frame            False\n",
       "transcript_id    False\n",
       "gene_id          False\n",
       "gene_name        False\n",
       "extra             True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for column with null values\n",
    "data.isnull().sum()\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Features in GFF : sample.gtf\n",
      "  transcript\n",
      "  exon\n",
      "  CDS\n"
     ]
    }
   ],
   "source": [
    "# Fetch all the unique features from the table \n",
    "print(f\"Unique Features in GFF : {filename}\")\n",
    "for i in data[\"feature\"].unique(): \n",
    "    print(f\"  {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records per features: \n",
      "exon          73\n",
      "transcript    26\n",
      "CDS            1\n",
      "Name: feature, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fetch number of records per feature\n",
    "print(f\"Number of records per features: \")\n",
    "feat_rec = data[\"feature\"].value_counts()\n",
    "print(feat_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chr1    100\n",
       "Name: Seqname, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch number of records per chromosomes\n",
    "data[\"Seqname\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of exons</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"AC018638.1\"</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AC092192.1\"</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AC093392.2\"</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AC093752.3\"</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AC114498.1\"</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AC240565.2\"</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AL627309.3\"</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AL669831.1\"</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AL669831.2\"</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AL731661.1\"</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"AP006222.2\"</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"CICP18\"</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"CICP3\"</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"LINC01409\"</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"OR4F21\"</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"RNU6-1199P\"</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"WBP1LP6\"</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Number of exons\n",
       "gene_name                    \n",
       "\"AC018638.1\"                1\n",
       "\"AC092192.1\"                1\n",
       "\"AC093392.2\"                3\n",
       "\"AC093752.3\"                1\n",
       "\"AC114498.1\"                4\n",
       "\"AC240565.2\"                3\n",
       "\"AL627309.3\"                2\n",
       "\"AL669831.1\"               21\n",
       "\"AL669831.2\"                2\n",
       "\"AL731661.1\"                3\n",
       "\"AP006222.2\"                2\n",
       "\"CICP18\"                    4\n",
       "\"CICP3\"                     2\n",
       "\"LINC01409\"                21\n",
       "\"OR4F21\"                    1\n",
       "\"RNU6-1199P\"                1\n",
       "\"WBP1LP6\"                   1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# featching exons per gene\n",
    "feature_type = \"exon\"\n",
    "sample = gffp.data.loc[:,[\"feature\",\"gene_name\"]]\n",
    "exon_per_geneid = sample[sample['feature'] == feature_type].groupby(\"gene_name\").count()\n",
    "exon_per_geneid.columns = [\"Number of exons\"]\n",
    "exon_per_geneid \n",
    "# Similarly number of feture type records can be counted per gene id "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
